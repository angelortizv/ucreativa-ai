{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43ac23c-1f45-44db-a7f8-e9a187874ff0",
   "metadata": {},
   "source": [
    "# Generación de Texto con Modelos de Lenguaje\n",
    "\n",
    "Este notebook explica paso a paso cómo generar texto con un modelo preentrenado utilizando la biblioteca `transformers` de Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df58feb-c360-4250-8507-a989c8baa5d3",
   "metadata": {},
   "source": [
    "## 1. Instalación y Configuración de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06042d02-11ee-42d9-b4d1-acaaec35cd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.47.0)\n",
      "Requirement already satisfied: torch in c:\\users\\pc master\\appdata\\roaming\\python\\python310\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2023.5.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lotly (c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc master\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8256b7-ff4e-49bd-a364-5e4b2f0df29c",
   "metadata": {},
   "source": [
    "## 2. Importación de Librerías Necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3567e4ad-9025-4062-9b1d-82f4cfec507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07492fda-0c59-4b63-b7ef-c2c8eef70c41",
   "metadata": {},
   "source": [
    "## 3. Carga del Modelo y Tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62599fc2-c1e9-4be4-9fe6-19e68e148023",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3080e14-b610-43ea-9ac7-7eead7fec269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el tokenizador y el modelo.\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef63b73e-8dea-4351-a444-dcbe2e1a1856",
   "metadata": {},
   "source": [
    "## 4. Configuración del Dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f642daa8-b9ba-479b-aad0-a5951b2b3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2689333-3a85-4efd-b7b4-71b9eaf1d823",
   "metadata": {},
   "source": [
    "## 5. Función de Generación de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7fedfd4-6e8e-4406-b5c5-9c3516029ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=50, temperature=1.0, top_k=50):\n",
    "    \"\"\"\n",
    "    Genera texto utilizando un modelo de lenguaje.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Texto inicial que guía la generación.\n",
    "        max_length (int): Longitud máxima del texto generado.\n",
    "        temperature (float): Controla la aleatoriedad (valores bajos = texto más predecible).\n",
    "        top_k (int): Limita el número de palabras candidatas en cada paso.\n",
    "\n",
    "    Returns:\n",
    "        str: Texto generado por el modelo.\n",
    "    \"\"\"\n",
    "    # Tokenizamos el prompt.\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generamos el texto.\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    # Decodificamos el texto generado.\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce49e004-3608-443e-84e0-ebdd37fd550b",
   "metadata": {},
   "source": [
    "## 6. Ejemplo Práctico de Generación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b46597-5b04-422a-9874-c0387165060d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Texto Generado ===\n",
      "\n",
      "Había una vez en un mundo lleno de misteriosa, si un á la fuerza.\n",
      "\n",
      "La familia no según hizo están con lucha de la ménós y los más de la cuatro.\n",
      "\n",
      "La mésophora para ha más quiel eston a las haciendas de la ménós y los más de las cuatro.\n",
      "\n",
      "Méso\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Había una vez en un mundo lleno de misterios\"\n",
    "generated_text = generate_text(prompt, max_length=100, temperature=0.7, top_k=50)\n",
    "\n",
    "print(\"\\n=== Texto Generado ===\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e2278-9ed6-4638-8bb0-b52d18c7c00b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
